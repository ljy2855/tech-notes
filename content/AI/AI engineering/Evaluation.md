해당 모델 자체가 어느정도의 성능을 내는지 벤치마크 지표가 필요

> 사용자가 느끼는 정성적인 평가, 객관적인 수치를 나타내는 정량적인 지표

모델 평가 기준

### Cross Entropy

Entropy ??

- 토큰이 평균적으로 얼마나 많은 정보를 담고 있는지 
- 

> 다음 토큰이 얼마나 예측하기 어려운지 표현

### Perplexity

> 다음 토큰을 예측할 때의 불확실성

사실 Cross Entropy랑 의미가 비슷해서 요즘엔 이거를 주로 사용

### Functioanl correctness


### 유사도 측정

- 비교 
평가자가 같은지 판단

- 정확한 일치

명확한 답이 존재하는 경우

- 어휘적 유사도

Fuzzy

n-gram

- 의미적 유사도


Embedding


### AI judge

MT-Bench에서 GPT-4가 사람의 일치도(81%)보다 85%로 더 높았음

```
다음 질의와 응답이 주어졌을 떄, 질의에 대한 응답이 얼마나 좋은지 평가하시오.
1부터 5까지 점수를 사용하시오.

1은 매우 나쁨을 의미한다.
5는 매우 좋음을 의미한다.
질의 : [질의]
응답 : [응답]
점수: [점수]
```


각 프레임워크에서 제공하는 AI 평가 기준

- Azure AI Foundry : 사실 기반성, 관련성, 일관성, 유창함, 유사성
- MLflow : 신뢰성, 적합성
- Langchain Crieria Evaluation : 간결성, 관련성, 정확성, 일관성, 유해성, 악의성, 유용성, 논란 가능성 ..

해당 기준들은 표준화 x

**Tip**
- LLM은 숫자보다 텍스트 처리를 더 잘함 -> 점수화보다 분류를 더 잘함
- 연속 점수보다 이산 점수 사용

한계
- 모델자체가 확률 기반이다보니, 비일관적인 평가가 발생가능
- 평가기준이 모호 (오픈 소스 도구들마다 표준화되어 있지 않음)
- 비용과 지연 시간
- 편향 :
	- 자기 편향 : 자신이 생성한 응답을 선호하는 경향
	- 위치 평햔 : 앞에 나온 응답을 선호하는 경향 
	- 장황성 편향 : 응답이 길수록 선호
	- 다만 모델이 커질수록 이런 편향은 줄어들수도 있음 (GPT-4)